### Port conventions (though there are many, many exceptions)
# 82xx - TBD
# 83xx - grapl plugin services, like grapl-aws-plugins
# 84xx - debugger ports (see vsc_debugger.py)

version: "3.8"
volumes:
  dgraph_export:
  pulumi_outputs:
    # This volume will be used to output Pulumi stack outputs that may
    # need to be accessible in test containers.

x-common-variables:
  read-only-pulumi-mnt: &read-only-pulumi-mnt
    type: volume
    source: pulumi_outputs
    target: /mnt/pulumi-outputs
    read_only: true
  aws-env: &aws-env
    GRAPL_AWS_ENDPOINT: ${GRAPL_AWS_ENDPOINT}
    GRAPL_AWS_ACCESS_KEY_ID: ${GRAPL_AWS_ACCESS_KEY_ID}
    GRAPL_AWS_ACCESS_KEY_SECRET: ${GRAPL_AWS_ACCESS_KEY_SECRET}
    AWS_DEFAULT_REGION: ${AWS_REGION} # boto3 prefers this one
    AWS_REGION: ${AWS_REGION}
  dgraph-env: &dgraph-env
    MG_ALPHAS: ${MG_ALPHAS}
  kafka-broker-env: &kafka-broker-env
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: "${ZOOKEEPER_HOST}:${ZOOKEEPER_PORT}"
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
    KAFKA_LISTENERS: PLAINTEXT://${KAFKA_BROKER_HOST}:9092
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_BROKER_HOST}:9092
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    KAFKA_JMX_PORT: ${KAFKA_JMX_PORT}
    KAFKA_JMX_HOSTNAME: localhost
    KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
  log-level: &log-level
    GRAPL_LOG_LEVEL: "${GRAPL_LOG_LEVEL:-ERROR}"
    RUST_LOG: "${RUST_LOG:-ERROR}"
  rust-backtrace: &rust-backtrace
    RUST_BACKTRACE: ${RUST_BACKTRACE}
  zookeeper-env: &zookeeper-env
    ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_PORT}
    ZOOKEEPER_TICK_TIME: 2000

services:
  ########################################################################
  # Cloud Infrastructure Dependencies
  ########################################################################

  dgraph:
    tty: false
    image: dgraph/standalone:v21.03.1
    ports:
      # required to access the RATEL interface for dgraph
      - 127.0.0.1:${DGRAPH_RATEL_HTTP_EXTERNAL_PUBLIC_PORT}:${DGRAPH_RATEL_HTTP_EXTERNAL_PUBLIC_PORT}
      # required for RATEL interface to operate properly
      - 127.0.0.1:${DGRAPH_ALPHA_HTTP_EXTERNAL_PUBLIC_PORT}:${DGRAPH_ALPHA_HTTP_EXTERNAL_PUBLIC_PORT}
    volumes:
      - type: volume
        source: dgraph_export
        # Hitting :8080/admin/export will force an export to be written to this directory.
        target: /dgraph/export
    networks:
      default:
        aliases:
          - ${DGRAPH_HOST}

  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    environment:
      <<: *zookeeper-env
    healthcheck:
      test:
        [
          "CMD",
          "echo",
          "ruok",
          "|",
          "nc",
          "-w",
          "2",
          "-q",
          "2",
          "localhost",
          "${ZOOKEEPER_PORT}",
          "|",
          "grep",
          "imok",
        ]
      retries: 5
      interval: 5s
      timeout: 30s
      start_period: 15s

  kafka-broker:
    image: confluentinc/cp-kafka:6.2.0
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "nc", "-vz", "kafka-broker", "${KAFKA_BROKER_PORT}"]
      retries: 5
      interval: 5s
      timeout: 30s
      start_period: 15s
    environment:
      <<: *kafka-broker-env

  # dev uses 1 big redis instance, prod has 1:1 redis per grapl
  # service... maybe transitory, this will eventually match prod
  redis:
    image: redis:latest
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # hack from https://stackoverflow.com/questions/54533308/disable-redis-persistence-in-docker
        # to disable persistence
        rm -f /data/dump.rdb
        redis-server
    healthcheck:
      test:
        - CMD-SHELL
        - |
          redis-cli -h 127.0.0.1 ping | grep PONG
      interval: 5s
      timeout: 10s
      start_period: 10s
    networks:
      default:
        aliases:
          - ${REDIS_HOST}

  localstack:
    #image: localstack/localstack-full:0.12.15 # -full includes elasticmq
    image: grapl/localstack:${TAG:-latest}
    ports:
      # We'll expose localstack's edge port for ease of use with
      # things like the AWS CLI, Pulumi, etc.
      - 127.0.0.1:${LOCALSTACK_PORT}:${LOCALSTACK_PORT}
    environment:
      - EDGE_PORT=${LOCALSTACK_PORT}
      - HOSTNAME_EXTERNAL=${LOCALSTACK_HOST}
      - SERVICES=apigateway,cloudwatch,dynamodb,ec2,events,iam,lambda,logs,s3,secretsmanager,sns,sqs
      - DEBUG=1
      # Once we put the lambdas behind the API gateway, overall test
      # time increased. Using the `docker` executor reliably takes at
      # least 2x the time of `docker-reuse`. However, the containers
      # generated are invisible to docker-compose, and Localstack
      # doesn't shut them down, so we have to manage that on our own
      # (see Makefile)
      - LAMBDA_EXECUTOR=docker-reuse
      - MAIN_CONTAINER_NAME=${COMPOSE_PROJECT_NAME}_localstack_1
      # Without this, the lambda containers are attached to the bridge network
      - LAMBDA_DOCKER_NETWORK=grapl-network
      - DATA_DIR=${DATA_DIR- }
      # The default SQS implementation uses `moto`; `elasticmq` is much more
      # fully-featured.
      - SQS_PROVIDER=elasticmq
    privileged: true # for docker lambda execution
    healthcheck:
      test:
        - CMD-SHELL
        - |
          export AWS_ACCESS_KEY_ID=${FAKE_AWS_ACCESS_KEY_ID}
          export AWS_SECRET_ACCESS_KEY=${FAKE_AWS_SECRET_ACCESS_KEY}
          aws --endpoint-url=http://${LOCALSTACK_HOST}:${LOCALSTACK_PORT} s3 ls
      # Probe failure during this period will not be counted towards the maximum number of retries
      start_period: 30s
      # Health check is executed every `interval` seconds.
      interval: 5s
      # If a single run of the check takes longer than `timeout` seconds then the check is considered to have failed.
      timeout: 10s
      # It takes `retries` consecutive failures of the health check for the container to be considered unhealthy.
      retries: 3
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    networks:
      default:
        aliases:
          - ${LOCALSTACK_HOST}

  ########################################################################
  # Rust Services
  ########################################################################

  sysmon-generator:
    image: grapl/sysmon-generator:${TAG:-latest}
    tty: false
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/unid-subgraphs-generated-bucket)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/sysmon-generator-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/sysmon-generator-queue)
        /sysmon-generator
    environment:
      <<: *aws-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  osquery-generator:
    image: grapl/osquery-generator:${TAG:-latest}
    tty: false
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/unid-subgraphs-generated-bucket)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/osquery-generator-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/osquery-generator-queue)
        /osquery-generator
    environment:
      <<: *aws-env
      DEPLOYMENT_NAME: ${DEPLOYMENT_NAME}
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  node-identifier:
    image: grapl/node-identifier:${TAG:-latest}
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/subgraphs-generated-bucket)
        export GRAPL_STATIC_MAPPING_TABLE=$$(cat /mnt/pulumi-outputs/static-mapping-table)
        export GRAPL_DYNAMIC_SESSION_TABLE=$$(cat /mnt/pulumi-outputs/dynamic-session-table)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-queue)
        /node-identifier
    environment:
      <<: *aws-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  node-identifier-retry:
    image: grapl/node-identifier-retry:${TAG:-latest}
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/subgraphs-generated-bucket)
        export GRAPL_STATIC_MAPPING_TABLE=$$(cat /mnt/pulumi-outputs/static-mapping-table)
        export GRAPL_DYNAMIC_SESSION_TABLE=$$(cat /mnt/pulumi-outputs/dynamic-session-table)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-dead-letter-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-retry-queue)
        /node-identifier-retry
    environment:
      <<: *aws-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  graph-merger:
    image: grapl/graph-merger:${TAG:-latest}
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/subgraphs-merged-bucket)
        export GRAPL_SCHEMA_TABLE=$$(cat /mnt/pulumi-outputs/schema-table)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/graph-merger-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/graph-merger-queue)
        /graph-merger
    environment:
      <<: *aws-env
      <<: *dgraph-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      dgraph:
        condition: service_started
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  analyzer-dispatcher:
    image: grapl/analyzer-dispatcher:${TAG:-latest}
    # The default entrypoint is ["/analyzer-dispatcher"];
    # "/busybox/sh" is the shell present present in the
    # distroless/cc:debug container.
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_ANALYZERS_BUCKET=$$(cat /mnt/pulumi-outputs/analyzers-bucket)
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/dispatched-analyzer-bucket)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/analyzer-dispatcher-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/analyzer-dispatcher-queue)
        /analyzer-dispatcher
    environment:
      <<: *aws-env
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      localstack:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  ########################################################################
  # Python Services
  ########################################################################

  analyzer-executor:
    image: grapl/analyzer-executor:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_ANALYZER_MATCHED_SUBGRAPHS_BUCKET=$$(cat /mnt/pulumi-outputs/analyzer-matched-subgraphs-bucket)
        export GRAPL_ANALYZERS_BUCKET=$$(cat /mnt/pulumi-outputs/analyzers-bucket)
        export GRAPL_MODEL_PLUGINS_BUCKET=$$(cat /mnt/pulumi-outputs/model-plugins-bucket)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/analyzer-executor-queue)
        ./analyzer-executor.pex
    environment:
      <<: *aws-env
      DEBUG_SERVICES: "${DEBUG_SERVICES:-}"
      <<: *dgraph-env
      GRPC_ENABLE_FORK_SUPPORT: "1"
      HITCACHE_ADDR: "${REDIS_HOST}"
      HITCACHE_PORT: "${REDIS_PORT}"
      IS_RETRY: "False"
      <<: *log-level
      MESSAGECACHE_ADDR: "${REDIS_HOST}"
      MESSAGECACHE_PORT: "${REDIS_PORT}"
      VSC_DEBUGGER_PORT: "${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}"
    tty: true
    ports:
      - 127.0.0.1:${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}:${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}
    depends_on:
      dgraph:
        condition: service_started
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  model-plugin-deployer:
    image: grapl/model-plugin-deployer:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_MODEL_PLUGINS_BUCKET=$$(cat /mnt/pulumi-outputs/model-plugins-bucket)
        export GRAPL_SCHEMA_TABLE=$$(cat /mnt/pulumi-outputs/schema-table)
        export GRAPL_SCHEMA_PROPERTIES_TABLE=$$(cat /mnt/pulumi-outputs/schema-properties-table)
        python3 -c 'import lambdex_handler; lambdex_handler.handler(None, None)'
    environment:
      <<: *aws-env
      <<: *dgraph-env
      IS_LOCAL: "True"
      <<: *log-level
    tty: true
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      provisioner:
        condition: service_completed_successfully
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt
    ports:
      - 127.0.0.1:${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}:${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}
    networks:
      default:
        aliases:
          - ${GRAPL_MODEL_PLUGIN_DEPLOYER_HOST}

  ########################################################################
  # Web Services
  ########################################################################

  nginx:
    image: nginxinc/nginx-unprivileged
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export API_GATEWAY_API_ID=$$(cat /mnt/pulumi-outputs/prod-api-id)
        /docker-entrypoint.sh nginx -g 'daemon off;'
    volumes:
      - ./etc/local_grapl/nginx_templates:/etc/nginx/templates
      - *read-only-pulumi-mnt
    ports:
      - "127.0.0.1:1234:${GRAPL_HTTP_FRONTEND_PORT}"
    environment:
      - GRAPL_GRAPHQL_HOST
      - GRAPL_GRAPHQL_PORT
      - GRAPL_MODEL_PLUGIN_DEPLOYER_HOST
      - GRAPL_MODEL_PLUGIN_DEPLOYER_PORT
      - LOCALSTACK_HOST
      - LOCALSTACK_PORT
    depends_on:
      model-plugin-deployer:
        condition: service_started
      graphql-endpoint:
        condition: service_started
      pulumi:
        # We must wait until Pulumi has created the API gateway so we
        # know what its URL is.
        condition: service_completed_successfully
      engagement-view-uploader:
        # nginx doesn't actually depend on engagement-view-uploader,
        # but we need *some* service to declare a dependency on the
        # engagement-view-uploader in order to catch non-0 exit codes
        condition: service_completed_successfully
    networks:
      default:
        aliases:
          - ${GRAPL_API_HOST}

  engagement-view-uploader:
    image: grapl/engagement-view:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_UX_BUCKET=$$(cat /mnt/pulumi-outputs/ux-bucket)
        ./upload_local.sh
    environment:
      <<: *aws-env
    depends_on:
      provisioner:
        condition: service_completed_successfully
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  graphql-endpoint:
    image: grapl/graphql-endpoint:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_SCHEMA_PROPERTIES_TABLE=$$(cat /mnt/pulumi-outputs/schema-properties-table)
        export GRAPL_SCHEMA_TABLE=$$(cat /mnt/pulumi-outputs/schema-table)
        ./start_potentially_with_debugger.sh
    environment:
      <<: *aws-env
      <<: *dgraph-env
      IS_LOCAL: "True"
      JWT_SECRET_ID: "JWT_SECRET_ID"
      PORT: ${GRAPL_GRAPHQL_PORT}
      DEBUG_SERVICES: "${DEBUG_SERVICES:-}"
      VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT: "${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}"
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      provisioner:
        condition: service_completed_successfully
      pulumi:
        condition: service_completed_successfully
    ports:
      - 127.0.0.1:${GRAPL_GRAPHQL_PORT}:${GRAPL_GRAPHQL_PORT}
      - 127.0.0.1:${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}:${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}
    networks:
      default:
        aliases:
          - ${GRAPL_GRAPHQL_HOST}
    volumes:
      - *read-only-pulumi-mnt

  grapl-notebook:
    image: grapl/notebook:${TAG:-latest}
    user: grapl
    environment:
      <<: *dgraph-env
    depends_on:
      - dgraph
    ports:
      - 127.0.0.1:${GRAPL_NOTEBOOK_PORT}:${GRAPL_NOTEBOOK_PORT}

  ########################################################################
  # Utility Services
  ########################################################################

  pulumi:
    image: grapl/local-pulumi:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        cd grapl
        pulumi login --local
        pulumi stack init local-grapl --non-interactive
        pulumi up --yes --skip-preview --stack=local-grapl

        # Write the necessary outputs to the shared volume, for access by other containers
        outputs=(
          analyzer-dispatcher-dead-letter-queue
          analyzer-dispatcher-queue
          analyzer-dispatcher-retry-queue
          analyzer-executor-queue
          analyzer-executor-retry-queue
          analyzer-matched-subgraphs-bucket
          analyzers-bucket
          dispatched-analyzer-bucket
          dynamic-session-table
          graph-merger-dead-letter-queue
          graph-merger-queue
          graph-merger-retry-queue
          model-plugins-bucket
          node-identifier-dead-letter-queue
          node-identifier-queue
          node-identifier-retry-queue
          osquery-generator-dead-letter-queue
          osquery-generator-queue
          osquery-generator-retry-queue
          osquery-log-bucket
          prod-api-id
          schema-properties-table
          schema-table
          static-mapping-table
          subgraphs-generated-bucket
          subgraphs-merged-bucket
          sysmon-generator-dead-letter-queue
          sysmon-generator-queue
          sysmon-generator-retry-queue
          sysmon-log-bucket
          unid-subgraphs-generated-bucket
          user-auth-table
          ux-bucket
        )
        for output in "$${outputs[@]}"; do
          pulumi stack output "$${output}" > "/home/grapl/pulumi-outputs/$${output}"
        done

    # Our local-grapl Pulumi stack is configured to communicate with
    # localhost. By participating in the network namespace of our
    # localstack container, we can use the same stack configuration
    # both inside this compose network, as well as from outside on our
    # workstations.
    network_mode: "service:localstack"
    volumes:
      - type: bind
        source: ./dist
        target: /home/grapl/dist
        read_only: true
      - type: volume
        source: pulumi_outputs
        target: /home/grapl/pulumi-outputs
        read_only: false # MUST be able to write
    environment:
      TAG:
      PULUMI_CONFIG_PASSPHRASE: local-grapl-passphrase
      # Other environment variables like MG_ALPHAS are passed in via
      # Pulumi.local-grapl.yaml
    depends_on:
      localstack:
        condition: service_healthy
      kafka-broker:
        condition: service_healthy

  provisioner:
    image: grapl/provisioner:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_SCHEMA_TABLE=$$(cat /mnt/pulumi-outputs/schema-table)
        export GRAPL_SCHEMA_PROPERTIES_TABLE=$$(cat /mnt/pulumi-outputs/schema-properties-table)
        export GRAPL_USER_AUTH_TABLE=$$(cat /mnt/pulumi-outputs/user-auth-table)

        python3 -c "import lambdex_handler; lambdex_handler.handler(None, None)"
    environment:
      <<: *aws-env
      <<: *dgraph-env
      GRAPL_LOG_LEVEL: "${GRAPL_LOG_LEVEL:-INFO}"
      DEPLOYMENT_NAME: "${DEPLOYMENT_NAME}"
      GRAPL_TEST_USER_NAME: "${DEPLOYMENT_NAME}-grapl-test-user"
    tty: true
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      pulumi:
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

networks:
  default:
    name: grapl-network
