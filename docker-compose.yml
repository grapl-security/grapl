### Port conventions (though there are many, many exceptions)
# 82xx - TBD
# 83xx - grapl plugin services, like grapl-aws-plugins
# 84xx - debugger ports (see vsc_debugger.py)

version: "3.8"
volumes:
  dgraph_export:

services:
<<<<<<< HEAD
=======
  ########################################################################
  # Cloud Infrastructure Dependencies
  ########################################################################

  dgraph:
    tty: false
    image: dgraph/standalone:v21.03.1
    ports:
      # required to access the RATEL interface for dgraph
      - 127.0.0.1:${DGRAPH_RATEL_HTTP_EXTERNAL_PUBLIC_PORT}:${DGRAPH_RATEL_HTTP_EXTERNAL_PUBLIC_PORT}
      # required for RATEL interface to operate properly
      - 127.0.0.1:${DGRAPH_ALPHA_HTTP_EXTERNAL_PUBLIC_PORT}:${DGRAPH_ALPHA_HTTP_EXTERNAL_PUBLIC_PORT}
    volumes:
      - type: volume
        source: dgraph_export
        # Hitting :8080/admin/export will force an export to be written to this directory.
        target: /dgraph/export
    networks:
      default:
        aliases:
          - ${DGRAPH_HOST}

  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    environment:
      <<: *zookeeper-env
    healthcheck:
      test:
        [
          "CMD",
          "echo",
          "ruok",
          "|",
          "nc",
          "-w",
          "2",
          "-q",
          "2",
          "localhost",
          "${ZOOKEEPER_PORT}",
          "|",
          "grep",
          "imok",
        ]
      retries: 5
      interval: 5s
      timeout: 30s
      start_period: 15s

  kafka-broker:
    image: confluentinc/cp-kafka:6.2.0
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "nc", "-vz", "kafka-broker", "${KAFKA_BROKER_PORT}"]
      retries: 5
      interval: 5s
      timeout: 30s
      start_period: 15s
    environment:
      <<: *kafka-broker-env

  # dev uses 1 big redis instance, prod has 1:1 redis per grapl
  # service... maybe transitory, this will eventually match prod
  redis:
    image: redis:latest
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # hack from https://stackoverflow.com/questions/54533308/disable-redis-persistence-in-docker
        # to disable persistence
        rm -f /data/dump.rdb
        redis-server
    healthcheck:
      test:
        - CMD-SHELL
        - |
          redis-cli -h 127.0.0.1 ping | grep PONG
      interval: 5s
      timeout: 10s
      start_period: 10s
    networks:
      default:
        aliases:
          - ${REDIS_HOST}

  localstack:
    image: localstack/localstack-full:0.12.15 # -full includes elasticmq
    ports:
      # We'll expose localstack's edge port for ease of use with
      # things like the AWS CLI, Pulumi, etc.
      - 127.0.0.1:${LOCALSTACK_PORT}:${LOCALSTACK_PORT}
    environment:
      - EDGE_PORT=${LOCALSTACK_PORT}
      - HOSTNAME_EXTERNAL=${LOCALSTACK_HOST}
      - SERVICES=apigateway,cloudwatch,dynamodb,ec2,events,iam,lambda,logs,s3,secretsmanager,sns,sqs
      - DEBUG=1
      # Once we put the lambdas behind the API gateway, overall test
      # time increased. Using the `docker` executor reliably takes at
      # least 2x the time of `docker-reuse`. However, the containers
      # generated are invisible to docker-compose, and Localstack
      # doesn't shut them down, so we have to manage that on our own
      # (see Makefile)
      - LAMBDA_EXECUTOR=docker-reuse
      - MAIN_CONTAINER_NAME=${COMPOSE_PROJECT_NAME}_localstack_1
      # Without this, the lambda containers are attached to the bridge network
      - LAMBDA_DOCKER_NETWORK=grapl-network
      - DATA_DIR=${DATA_DIR- }
      # The default SQS implementation uses `moto`; `elasticmq` is much more
      # fully-featured.
      - SQS_PROVIDER=elasticmq
    privileged: true # for docker lambda execution
    healthcheck:
      test:
        - CMD-SHELL
        - |
          export AWS_ACCESS_KEY_ID=${FAKE_AWS_ACCESS_KEY_ID}
          export AWS_SECRET_ACCESS_KEY=${FAKE_AWS_SECRET_ACCESS_KEY}
          aws --endpoint-url=http://${LOCALSTACK_HOST}:${LOCALSTACK_PORT} s3 ls
      # Probe failure during this period will not be counted towards the maximum number of retries
      start_period: 30s
      # Health check is executed every `interval` seconds.
      interval: 5s
      # If a single run of the check takes longer than `timeout` seconds then the check is considered to have failed.
      timeout: 10s
      # It takes `retries` consecutive failures of the health check for the container to be considered unhealthy.
      retries: 3
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    networks:
      default:
        aliases:
          - ${LOCALSTACK_HOST}

  ########################################################################
  # Rust Services
  ########################################################################

  sysmon-generator:
    image: grapl/sysmon-generator:${TAG:-latest}
    tty: false
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/unid-subgraphs-generated-bucket)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/sysmon-generator-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/sysmon-generator-queue)
        /sysmon-generator
    environment:
      <<: *aws-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  osquery-generator:
    image: grapl/osquery-generator:${TAG:-latest}
    tty: false
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/unid-subgraphs-generated-bucket)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/osquery-generator-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/osquery-generator-queue)
        /osquery-generator
    environment:
      <<: *aws-env
      DEPLOYMENT_NAME: ${DEPLOYMENT_NAME}
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  node-identifier:
    image: grapl/node-identifier:${TAG:-latest}
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/subgraphs-generated-bucket)
        export GRAPL_STATIC_MAPPING_TABLE=$$(cat /mnt/pulumi-outputs/static-mapping-table)
        export GRAPL_DYNAMIC_SESSION_TABLE=$$(cat /mnt/pulumi-outputs/dynamic-session-table)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-queue)
        /node-identifier
    environment:
      <<: *aws-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  node-identifier-retry:
    image: grapl/node-identifier-retry:${TAG:-latest}
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/subgraphs-generated-bucket)
        export GRAPL_STATIC_MAPPING_TABLE=$$(cat /mnt/pulumi-outputs/static-mapping-table)
        export GRAPL_DYNAMIC_SESSION_TABLE=$$(cat /mnt/pulumi-outputs/dynamic-session-table)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-dead-letter-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/node-identifier-retry-queue)
        /node-identifier-retry
    environment:
      <<: *aws-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  graph-merger:
    image: grapl/graph-merger:${TAG:-latest}
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        # TODO: Rename this variable to be in line with our others?
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/subgraphs-merged-bucket)
        export GRAPL_SCHEMA_TABLE=$$(cat /mnt/pulumi-outputs/schema-table)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/graph-merger-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/graph-merger-queue)
        /graph-merger
    environment:
      <<: *aws-env
      <<: *dgraph-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      dgraph:
        condition: service_started
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  analyzer-dispatcher:
    image: grapl/analyzer-dispatcher:${TAG:-latest}
    # The default entrypoint is ["/analyzer-dispatcher"];
    # "/busybox/sh" is the shell present present in the
    # distroless/cc:debug container.
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_ANALYZERS_BUCKET=$$(cat /mnt/pulumi-outputs/analyzers-bucket)
        export DEST_BUCKET_NAME=$$(cat /mnt/pulumi-outputs/dispatched-analyzer-bucket)
        export DEAD_LETTER_QUEUE_URL=$$(cat /mnt/pulumi-outputs/analyzer-dispatcher-retry-queue)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/analyzer-dispatcher-queue)
        /analyzer-dispatcher
    environment:
      <<: *aws-env
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    depends_on:
      localstack:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt
  
  # TODO: Rename once we deprecate `model-plugin-deployer-classic`
  model-plugin-deployer-v2:
    image: grapl/model-plugin-deployer-v2:${TAG:-latest}
    entrypoint: ["/busybox/sh", "-o", "errexit", "-o", "nounset", "-c"]
    command: 
      - |
          /model-plugin-deployer
    environment:
      GRAPL_MODEL_PLUGIN_DEPLOYER_V2_PORT: "${GRAPL_MODEL_PLUGIN_DEPLOYER_V2_PORT}"
      <<: *log-level
      <<: *rust-backtrace
    tty: false
    ports:
      - 127.0.0.1:${GRAPL_MODEL_PLUGIN_DEPLOYER_V2_PORT}:${GRAPL_MODEL_PLUGIN_DEPLOYER_V2_PORT}
    networks:
      default:
        aliases:
          - ${GRAPL_MODEL_PLUGIN_DEPLOYER_V2_HOST}


  ########################################################################
  # Python Services
  ########################################################################

  analyzer-executor:
    image: grapl/analyzer-executor:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_ANALYZER_MATCHED_SUBGRAPHS_BUCKET=$$(cat /mnt/pulumi-outputs/analyzer-matched-subgraphs-bucket)
        export GRAPL_ANALYZERS_BUCKET=$$(cat /mnt/pulumi-outputs/analyzers-bucket)
        export GRAPL_MODEL_PLUGINS_BUCKET=$$(cat /mnt/pulumi-outputs/model-plugins-bucket)
        export SOURCE_QUEUE_URL=$$(cat /mnt/pulumi-outputs/analyzer-executor-queue)
        python3 analyzer_executor/src/run.py
    environment:
      <<: *aws-env
      DEBUG_SERVICES: "${DEBUG_SERVICES:-}"
      <<: *dgraph-env
      GRPC_ENABLE_FORK_SUPPORT: "1"
      HITCACHE_ADDR: "${REDIS_HOST}"
      HITCACHE_PORT: "${REDIS_PORT}"
      IS_RETRY: "False"
      <<: *log-level
      MESSAGECACHE_ADDR: "${REDIS_HOST}"
      MESSAGECACHE_PORT: "${REDIS_PORT}"
      VSC_DEBUGGER_PORT: "${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}"
    tty: true
    ports:
      - 127.0.0.1:${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}:${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}
    depends_on:
      dgraph:
        condition: service_started
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  # On deprecation path
  model-plugin-deployer-v1:
    image: grapl/model-plugin-deployer-v1:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_MODEL_PLUGINS_BUCKET=$$(cat /mnt/pulumi-outputs/model-plugins-bucket)
        export GRAPL_SCHEMA_TABLE=$$(cat /mnt/pulumi-outputs/schema-table)
        export GRAPL_SCHEMA_PROPERTIES_TABLE=$$(cat /mnt/pulumi-outputs/schema-properties-table)

        . venv/bin/activate
        cd /home/grapl/app
        chalice local \
          --no-autoreload \
          --host=0.0.0.0 \
          --port=${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}

    environment:
      <<: *aws-env
      <<: *dgraph-env
      IS_LOCAL: "True"
      <<: *log-level
    tty: true
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      provisioner:
        condition: service_completed_successfully
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt
    ports:
      - 127.0.0.1:${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}:${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}
    networks:
      default:
        aliases:
          - ${GRAPL_MODEL_PLUGIN_DEPLOYER_HOST}

  ########################################################################
  # Web Services
  ########################################################################

  nginx:
    image: nginxinc/nginx-unprivileged
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export API_GATEWAY_API_ID=$$(cat /mnt/pulumi-outputs/prod-api-id)
        /docker-entrypoint.sh nginx -g 'daemon off;'
    volumes:
      - ./etc/local_grapl/nginx_templates:/etc/nginx/templates
      - *read-only-pulumi-mnt
    ports:
      - "127.0.0.1:1234:${GRAPL_HTTP_FRONTEND_PORT}"
    environment:
      - GRAPL_GRAPHQL_HOST
      - GRAPL_GRAPHQL_PORT
      - GRAPL_MODEL_PLUGIN_DEPLOYER_HOST
      - GRAPL_MODEL_PLUGIN_DEPLOYER_PORT
      - LOCALSTACK_HOST
      - LOCALSTACK_PORT
    depends_on:
      model-plugin-deployer-v1:
        condition: service_started
      graphql-endpoint:
        condition: service_started
      pulumi:
        # We must wait until Pulumi has created the API gateway so we
        # know what its URL is.
        condition: service_completed_successfully
      engagement-view-uploader:
        # nginx doesn't actually depend on engagement-view-uploader,
        # but we need *some* service to declare a dependency on the
        # engagement-view-uploader in order to catch non-0 exit codes
        condition: service_completed_successfully
    networks:
      default:
        aliases:
          - ${GRAPL_API_HOST}

  engagement-view-uploader:
    image: grapl/engagement-view:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_UX_BUCKET=$$(cat /mnt/pulumi-outputs/ux-bucket)
        ./upload_local.sh
    environment:
      <<: *aws-env
    depends_on:
      provisioner:
        condition: service_completed_successfully
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - *read-only-pulumi-mnt

  graphql-endpoint:
    image: grapl/graphql-endpoint:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_SCHEMA_PROPERTIES_TABLE=$$(cat /mnt/pulumi-outputs/schema-properties-table)
        export GRAPL_SCHEMA_TABLE=$$(cat /mnt/pulumi-outputs/schema-table)
        ./start_potentially_with_debugger.sh
    environment:
      <<: *aws-env
      <<: *dgraph-env
      IS_LOCAL: "True"
      JWT_SECRET_ID: "JWT_SECRET_ID"
      PORT: ${GRAPL_GRAPHQL_PORT}
      DEBUG_SERVICES: "${DEBUG_SERVICES:-}"
      VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT: "${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}"
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      provisioner:
        condition: service_completed_successfully
      pulumi:
        condition: service_completed_successfully
    ports:
      - 127.0.0.1:${GRAPL_GRAPHQL_PORT}:${GRAPL_GRAPHQL_PORT}
      - 127.0.0.1:${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}:${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}
    networks:
      default:
        aliases:
          - ${GRAPL_GRAPHQL_HOST}
    volumes:
      - *read-only-pulumi-mnt

  grapl-notebook:
    image: grapl/notebook:${TAG:-latest}
    user: grapl
    environment:
      <<: *dgraph-env
    depends_on:
      - dgraph
    ports:
      - 127.0.0.1:${GRAPL_NOTEBOOK_PORT}:${GRAPL_NOTEBOOK_PORT}

  ########################################################################
  # Utility Services
  ########################################################################

>>>>>>> I am one error away from a functional, unfeatureful deploy_model RPC
  pulumi:
    image: grapl/local-pulumi:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        cd grapl
        pulumi login --local
        pulumi stack init local-grapl --non-interactive
        pulumi up --yes --skip-preview --stack=local-grapl

    volumes:
      - type: bind
        source: ./dist
        target: /home/grapl/dist
        read_only: true
    environment:
      TAG:
      PULUMI_CONFIG_PASSPHRASE: local-grapl-passphrase
      # This gets exported to True by `make test-integration`
      SHOULD_DEPLOY_INTEGRATION_TESTS: "${SHOULD_DEPLOY_INTEGRATION_TESTS:-False}"
      # This gets exported to True by `make test-e2e`
      SHOULD_DEPLOY_E2E_TESTS: "${SHOULD_DEPLOY_E2E_TESTS:-False}"
      DOCKER_USER: "${UID}:${GID}"
      GRAPL_ROOT: "${GRAPL_ROOT}"
      # Other environment variables like MG_ALPHAS are passed in via
      # Pulumi.local-grapl.yaml
    extra_hosts:
      # Expose the host Linux machine, despite being on the Grapl network.
      # This lets Pulumi talk to the host's Nomad
      - "host.docker.internal:host-gateway"
