### Port conventions (though there are many, many exceptions)
# 82xx - TBD
# 83xx - grapl plugin services, like grapl-aws-plugins
# 84xx - debugger ports (see vsc_debugger.py)

version: "3.8"
volumes:
  dgraph_export:
  pulumi_outputs:
    # This volume will be used to output Pulumi stack outputs that may
    # need to be accessible in test containers.

x-common-variables:
  aws-env: &aws-env
    GRAPL_AWS_ENDPOINT: ${GRAPL_AWS_ENDPOINT}
    GRAPL_AWS_ACCESS_KEY_ID: ${GRAPL_AWS_ACCESS_KEY_ID}
    GRAPL_AWS_ACCESS_KEY_SECRET: ${GRAPL_AWS_ACCESS_KEY_SECRET}
    AWS_DEFAULT_REGION: ${AWS_REGION} # boto3 prefers this one
    AWS_REGION: ${AWS_REGION}
  dgraph-env: &dgraph-env
    MG_ALPHAS: ${MG_ALPHAS}
  # TODO: Ensure these are matched with what's in provision_local_identity_table.py
  dynamodb-mapping-tables: &dynamodb-mapping-tables
    ASSET_ID_MAPPINGS: ${DEPLOYMENT_NAME}-asset_id_mappings
    DYNAMIC_SESSION_TABLE: ${DEPLOYMENT_NAME}-dynamic_session_table
    FILE_HISTORY_TABLE: ${DEPLOYMENT_NAME}-file_history_table
    INBOUND_CONNECTION_HISTORY_TABLE: ${DEPLOYMENT_NAME}-inbound_connection_history_table
    IP_CONNECTION_HISTORY_TABLE: ${DEPLOYMENT_NAME}-ip_connection_history_table
    NETWORK_CONNECTION_HISTORY_TABLE: ${DEPLOYMENT_NAME}-network_connection_history_table
    OUTBOUND_CONNECTION_HISTORY_TABLE: ${DEPLOYMENT_NAME}-outbound_connection_history_table
    PROCESS_HISTORY_TABLE: ${DEPLOYMENT_NAME}-process_history_table
    STATIC_MAPPING_TABLE: ${DEPLOYMENT_NAME}-static_mapping_table
  kafka-broker-env: &kafka-broker-env
    KAFKA_BROKER_ID: 1
    KAFKA_ZOOKEEPER_CONNECT: "${ZOOKEEPER_HOST}:${ZOOKEEPER_PORT}"
    KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
    KAFKA_LISTENERS: PLAINTEXT://${KAFKA_BROKER_HOST}:9092
    KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${KAFKA_BROKER_HOST}:9092
    KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
    KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
    KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
    KAFKA_JMX_PORT: ${KAFKA_JMX_PORT}
    KAFKA_JMX_HOSTNAME: localhost
    KAFKA_LOG4J_ROOT_LOGLEVEL: INFO
  log-level: &log-level
    GRAPL_LOG_LEVEL: "${GRAPL_LOG_LEVEL:-ERROR}"
    RUST_LOG: "${RUST_LOG:-ERROR}"
  rust-backtrace: &rust-backtrace
    RUST_BACKTRACE: ${RUST_BACKTRACE}
  zookeeper-env: &zookeeper-env
    ZOOKEEPER_CLIENT_PORT: ${ZOOKEEPER_PORT}
    ZOOKEEPER_TICK_TIME: 2000

services:
  ########################################################################
  # Cloud Infrastructure Dependencies
  ########################################################################

  dgraph:
    tty: false
    image: dgraph/standalone:v20.07.1
    ports:
      # required to access the RATEL interface for dgraph
      - 127.0.0.1:${DGRAPH_RATEL_HTTP_EXTERNAL_PUBLIC_PORT}:${DGRAPH_RATEL_HTTP_EXTERNAL_PUBLIC_PORT}
      # required for RATEL interface to operate properly
      - 127.0.0.1:${DGRAPH_ALPHA_HTTP_EXTERNAL_PUBLIC_PORT}:${DGRAPH_ALPHA_HTTP_EXTERNAL_PUBLIC_PORT}
    volumes:
      - type: volume
        source: dgraph_export
        # Hitting :8080/admin/export will force an export to be written to this directory.
        target: /dgraph/export
    networks:
      default:
        aliases:
          - ${DGRAPH_HOST}

  zookeeper:
    image: confluentinc/cp-zookeeper:6.2.0
    environment:
      <<: *zookeeper-env
    healthcheck:
      test:
        [
          "CMD",
          "echo",
          "ruok",
          "|",
          "nc",
          "-w",
          "2",
          "-q",
          "2",
          "localhost",
          "${ZOOKEEPER_PORT}",
          "|",
          "grep",
          "imok",
        ]
      retries: 5
      interval: 5s
      timeout: 30s
      start_period: 15s

  kafka-broker:
    image: confluentinc/cp-kafka:6.2.0
    depends_on:
      zookeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "nc", "-vz", "kafka-broker", "${KAFKA_BROKER_PORT}"]
      retries: 5
      interval: 5s
      timeout: 30s
      start_period: 15s
    environment:
      <<: *kafka-broker-env

  # dev uses 1 big redis instance, prod has 1:1 redis per grapl
  # service... maybe transitory, this will eventually match prod
  redis:
    image: redis:latest
    command: |
      sh -c "
        # hack from https://stackoverflow.com/questions/54533308/disable-redis-persistence-in-docker
        # to disable persistence
        rm -f /data/dump.rdb && redis-server
      "
    healthcheck:
      test: bash -c 'redis-cli -h 127.0.0.1 ping | grep PONG'
      interval: 5s
      timeout: 10s
      start_period: 10s
    networks:
      default:
        aliases:
          - ${REDIS_HOST}

  localstack:
    image: localstack/localstack:0.12.15
    ports:
      # We'll expose localstack's edge port for ease of use with
      # things like the AWS CLI, Pulumi, etc.
      - 127.0.0.1:${LOCALSTACK_PORT}:${LOCALSTACK_PORT}
    environment:
      - IMAGE_NAME=localstack/localstack:0.12.15
      - EDGE_PORT=${LOCALSTACK_PORT}
      - HOSTNAME_EXTERNAL=${LOCALSTACK_HOST}
      - SERVICES=apigateway,cloudwatch,dynamodb,ec2,events,iam,lambda,logs,s3,secretsmanager,sns,sqs
      - DEBUG=1
      # Once we put the lambdas behind the API gateway, overall test
      # time increased. Using the `docker` executor reliably takes at
      # least 2x the time of `docker-reuse`. However, the containers
      # generated are invisible to docker-compose, and Localstack
      # doesn't shut them down, so we have to manage that on our own
      # (see Makefile)
      - LAMBDA_EXECUTOR=docker-reuse
      - MAIN_CONTAINER_NAME=${COMPOSE_PROJECT_NAME}_localstack_1
      # Without this, the lambda containers are attached to the bridge network
      - LAMBDA_DOCKER_NETWORK=grapl-network
      - DATA_DIR=${DATA_DIR- }
    privileged: true # for docker lambda execution
    healthcheck:
      test: |
        bash -c '
          export AWS_ACCESS_KEY_ID=${FAKE_AWS_ACCESS_KEY_ID} &&
          export AWS_SECRET_ACCESS_KEY=${FAKE_AWS_SECRET_ACCESS_KEY} &&
          aws --endpoint-url=http://${LOCALSTACK_HOST}:${LOCALSTACK_PORT} s3 ls
        '
      # Probe failure during this period will not be counted towards the maximum number of retries
      start_period: 30s
      # Health check is executed every `interval` seconds.
      interval: 5s
      # If a single run of the check takes longer than `timeout` seconds then the check is considered to have failed.
      timeout: 10s
      # It takes `retries` consecutive failures of the health check for the container to be considered unhealthy.
      retries: 3
    volumes:
      - "/var/run/docker.sock:/var/run/docker.sock"
    networks:
      default:
        aliases:
          - ${LOCALSTACK_HOST}

  ########################################################################
  # Rust Services
  ########################################################################

  sysmon-generator:
    image: grapl/sysmon-generator:${TAG:-latest}
    tty: false
    environment:
      <<: *aws-env
      DEAD_LETTER_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-sysmon-generator-dead-letter-queue"
      DEST_BUCKET_NAME: "${DEPLOYMENT_NAME}-unid-subgraphs-generated-bucket"
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      RETRY_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/000000000000/${DEPLOYMENT_NAME}-sysmon-generator-retry-queue"
      SOURCE_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/000000000000/${DEPLOYMENT_NAME}-sysmon-generator-queue"
      <<: *rust-backtrace
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy

  osquery-generator:
    image: grapl/osquery-generator:${TAG:-latest}
    tty: false
    environment:
      <<: *aws-env
      DEPLOYMENT_NAME: ${DEPLOYMENT_NAME}
      DEAD_LETTER_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-osquery-generator-dead-letter-queue"
      DEST_BUCKET_NAME: "${DEPLOYMENT_NAME}-unid-subgraphs-generated-bucket"
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      RETRY_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-osquery-generator-retry-queue"
      SOURCE_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-osquery-generator-queue"
      <<: *rust-backtrace
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy

  node-identifier:
    image: grapl/node-identifier:${TAG:-latest}
    environment:
      <<: *aws-env
      DEAD_LETTER_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-node-identifier-dead-letter-queue"
      DEST_BUCKET_NAME: "${DEPLOYMENT_NAME}-subgraphs-generated-bucket"
      <<: *dynamodb-mapping-tables
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      RETRY_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-node-identifier-retry-queue"
      SOURCE_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-node-identifier-queue"
      <<: *rust-backtrace
    tty: false
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy

  node-identifier-retry:
    image: grapl/node-identifier-retry:${TAG:-latest}
    environment:
      <<: *aws-env
      DEAD_LETTER_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-node-identifier-dead-letter-queue"
      DEST_BUCKET_NAME: "${DEPLOYMENT_NAME}-subgraphs-generated-bucket"
      <<: *dynamodb-mapping-tables
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      <<: *log-level
      RETRY_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-node-identifier-dead-letter-queue"
      SOURCE_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-node-identifier-retry-queue"
      <<: *rust-backtrace
    tty: false
    depends_on:
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy

  graph-merger:
    image: grapl/graph-merger:${TAG:-latest}
    environment:
      <<: *aws-env
      DEAD_LETTER_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-graph-merger-dead-letter-queue"
      DEST_BUCKET_NAME: "${DEPLOYMENT_NAME}-subgraphs-merged-bucket"
      <<: *dgraph-env
      REDIS_ENDPOINT: "${REDIS_ENDPOINT}"
      GRAPL_SCHEMA_TABLE: "${DEPLOYMENT_NAME}-grapl_schema_table"
      <<: *log-level
      RETRY_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-graph-merger-retry-queue"
      SOURCE_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-graph-merger-queue"
      <<: *rust-backtrace
    tty: false
    depends_on:
      dgraph:
        condition: service_started
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy

  analyzer-dispatcher:
    image: grapl/analyzer-dispatcher:${TAG:-latest}
    environment:
      ANALYZER_BUCKET: "${DEPLOYMENT_NAME}-analyzers-bucket"
      <<: *aws-env
      DEAD_LETTER_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-analyzer-dispatcher-dead-letter-queue"
      DEST_BUCKET_NAME: "${DEPLOYMENT_NAME}-dispatched-analyzer-bucket"
      <<: *log-level
      RETRY_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-analyzer-dispatcher-retry-queue"
      SOURCE_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-analyzer-dispatcher-queue"
      <<: *rust-backtrace
    tty: false
    depends_on:
      localstack:
        condition: service_healthy

  ########################################################################
  # Python Services
  ########################################################################

  analyzer-executor:
    image: grapl/analyzer-executor:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_ANALYZER_MATCHED_SUBGRAPHS_BUCKET=$$(cat /pulumi-outputs/analyzer-matched-subgraphs-bucket)
        export GRAPL_ANALYZERS_BUCKET=$$(cat /pulumi-outputs/analyzers-bucket)
        export GRAPL_MODEL_PLUGINS_BUCKET=$$(cat /pulumi-outputs/model-plugins-bucket)
        python3 analyzer_executor/src/run.py
    environment:
      <<: *aws-env
      DEBUG_SERVICES: "${DEBUG_SERVICES:-}"
      <<: *dgraph-env
      GRPC_ENABLE_FORK_SUPPORT: "1"
      HITCACHE_ADDR: "${REDIS_HOST}"
      HITCACHE_PORT: "${REDIS_PORT}"
      IS_RETRY: "False"
      <<: *log-level
      MESSAGECACHE_ADDR: "${REDIS_HOST}"
      MESSAGECACHE_PORT: "${REDIS_PORT}"
      RETRY_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-analyzer-executor-retry-queue"
      SOURCE_QUEUE_URL: "${GRAPL_AWS_ENDPOINT}/queue/${DEPLOYMENT_NAME}-analyzer-executor-queue"
      VSC_DEBUGGER_PORT: "${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}"
    tty: true
    ports:
      - 127.0.0.1:${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}:${VSC_DEBUGGER_PORT_FOR_ANALYZER_EXECUTOR}
    depends_on:
      dgraph:
        condition: service_started
      provisioner:
        condition: service_completed_successfully
      localstack:
        condition: service_healthy
      redis:
        condition: service_healthy
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - type: volume
        source: pulumi_outputs
        target: /pulumi-outputs
        read_only: true

  model-plugin-deployer:
    image: grapl/model-plugin-deployer:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        export GRAPL_MODEL_PLUGINS_BUCKET=$$(cat /pulumi-outputs/model-plugins-bucket)
        . venv/bin/activate
        cd /home/grapl/app
        chalice local \
          --no-autoreload \
          --host=0.0.0.0 \
          --port=${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}

    environment:
      <<: *aws-env
      <<: *dgraph-env
      IS_LOCAL: "True"
      <<: *log-level
      UX_BUCKET_URL: "localhost"
    tty: true
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      provisioner:
        condition: service_completed_successfully
      pulumi:
        # We must wait until Pulumi has created the buckets to know what their names are
        condition: service_completed_successfully
    volumes:
      - type: volume
        source: pulumi_outputs
        target: /pulumi-outputs
        read_only: true
    ports:
      - 127.0.0.1:${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}:${GRAPL_MODEL_PLUGIN_DEPLOYER_PORT}
    networks:
      default:
        aliases:
          - ${GRAPL_MODEL_PLUGIN_DEPLOYER_HOST}

  ########################################################################
  # Web Services
  ########################################################################

  nginx:
    image: nginxinc/nginx-unprivileged
    command: |
      /bin/bash -c "
        export API_GATEWAY_API_ID=$$(cat /pulumi-outputs/prod-api-id) &&
        /docker-entrypoint.sh nginx -g 'daemon off;'
      "
    volumes:
      - ./etc/local_grapl/nginx_templates:/etc/nginx/templates
      - type: volume
        source: pulumi_outputs
        target: /pulumi-outputs
        read_only: true
    ports:
      - "127.0.0.1:1234:${GRAPL_HTTP_FRONTEND_PORT}"
    environment:
      - GRAPL_GRAPHQL_HOST
      - GRAPL_GRAPHQL_PORT
      - GRAPL_MODEL_PLUGIN_DEPLOYER_HOST
      - GRAPL_MODEL_PLUGIN_DEPLOYER_PORT
      - LOCALSTACK_HOST
      - LOCALSTACK_PORT
    depends_on:
      model-plugin-deployer:
        condition: service_started
      graphql-endpoint:
        condition: service_started
      pulumi:
        # We must wait until Pulumi has created the API gateway so we
        # know what its URL is.
        condition: service_completed_successfully
      engagement-view-uploader:
        # nginx doesn't actually depend on engagement-view-uploader,
        # but we need *some* service to declare a dependency on the
        # engagement-view-uploader in order to catch non-0 exit codes
        condition: service_completed_successfully
    networks:
      default:
        aliases:
          - ${GRAPL_API_HOST}

  engagement-view-uploader:
    image: grapl/engagement-view:${TAG:-latest}
    command: |
      /bin/bash -c "./upload_local.sh"
    environment:
      <<: *aws-env
    depends_on:
      provisioner:
        condition: service_completed_successfully

  graphql-endpoint:
    image: grapl/graphql-endpoint:${TAG:-latest}
    command: bash -c "./start_potentially_with_debugger.sh"
    environment:
      <<: *aws-env
      <<: *dgraph-env
      IS_LOCAL: "True"
      JWT_SECRET_ID: "JWT_SECRET_ID"
      PORT: ${GRAPL_GRAPHQL_PORT}
      GRAPL_SCHEMA_PROPERTIES_TABLE: "${DEPLOYMENT_NAME}-grapl_schema_properties_table"
      GRAPL_SCHEMA_TABLE: "${DEPLOYMENT_NAME}-grapl_schema_table"
      DEBUG_SERVICES: "${DEBUG_SERVICES:-}"
      VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT: "${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}"
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      provisioner:
        condition: service_completed_successfully
    ports:
      - 127.0.0.1:${GRAPL_GRAPHQL_PORT}:${GRAPL_GRAPHQL_PORT}
      - 127.0.0.1:${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}:${VSC_DEBUGGER_PORT_FOR_GRAPHQL_ENDPOINT}
    networks:
      default:
        aliases:
          - ${GRAPL_GRAPHQL_HOST}

  grapl-notebook:
    image: grapl/notebook:${TAG:-latest}
    user: grapl
    environment:
      <<: *dgraph-env
    depends_on:
      - dgraph
    ports:
      - 127.0.0.1:${GRAPL_NOTEBOOK_PORT}:${GRAPL_NOTEBOOK_PORT}

  ########################################################################
  # Utility Services
  ########################################################################

  pulumi:
    image: grapl/local-pulumi:${TAG:-latest}
    entrypoint: ["/bin/bash", "-o", "errexit", "-o", "nounset", "-c"]
    command:
      - |
        cd grapl
        pulumi login --local
        pulumi stack init local-grapl --non-interactive
        pulumi up --yes --skip-preview --stack=local-grapl

        # Write the necessary outputs to the shared volume, for access by other containers
        outputs=(
          analyzer-matched-subgraphs-bucket
          analyzers-bucket
          model-plugins-bucket
          prod-api-id
        )
        for output in "$${outputs[@]}"; do
          pulumi stack output "$${output}" > "/home/grapl/pulumi-outputs/$${output}"
        done

    # Our local-grapl Pulumi stack is configured to communicate with
    # localhost. By participating in the network namespace of our
    # localstack container, we can use the same stack configuration
    # both inside this compose network, as well as from outside on our
    # workstations.
    network_mode: "service:localstack"
    volumes:
      - type: bind
        source: ./dist
        target: /home/grapl/dist
        read_only: true
      - type: volume
        source: pulumi_outputs
        target: /home/grapl/pulumi-outputs
        read_only: false
    environment:
      TAG:
      PULUMI_CONFIG_PASSPHRASE: local-grapl-passphrase
      # Other environment variables like MG_ALPHAS are passed in via
      # Pulumi.local-grapl.yaml
    depends_on:
      localstack:
        condition: service_healthy
      kafka-broker:
        condition: service_healthy

  provisioner:
    image: grapl/provisioner:${TAG:-latest}
    command: |
      /bin/bash -c "
          python -c 'import lambdex_handler; lambdex_handler.handler(None, None)'
      "
    environment:
      <<: *aws-env
      <<: *dgraph-env
      GRAPL_LOG_LEVEL: "${GRAPL_LOG_LEVEL:-INFO}"
      DEPLOYMENT_NAME: "${DEPLOYMENT_NAME}"
      GRAPL_TEST_USER_NAME: "${DEPLOYMENT_NAME}-grapl-test-user"
    tty: true
    depends_on:
      dgraph:
        condition: service_started
      localstack:
        condition: service_healthy
      pulumi:
        condition: service_completed_successfully

networks:
  default:
    name: grapl-network
